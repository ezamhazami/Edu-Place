{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6188d85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ask pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7376281",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 23 key-value pairs and 195 tensors from C:\\Users\\ASUS\\Downloads\\Phi-3-mini-4k-instruct-fp16.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = phi3\n",
      "llama_model_loader: - kv   1:                               general.name str              = Phi3\n",
      "llama_model_loader: - kv   2:                        phi3.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                      phi3.embedding_length u32              = 3072\n",
      "llama_model_loader: - kv   4:                   phi3.feed_forward_length u32              = 8192\n",
      "llama_model_loader: - kv   5:                           phi3.block_count u32              = 32\n",
      "llama_model_loader: - kv   6:                  phi3.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   7:               phi3.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv   8:      phi3.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv   9:                  phi3.rope.dimension_count u32              = 96\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 1\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                         tokenizer.ggml.pre str              = default\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32064]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32064]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32064]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 32000\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 32000\n",
      "llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  22:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type  f16:  130 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = F16\n",
      "print_info: file size   = 7.12 GiB (16.00 BPW) \n",
      "init_tokenizer: initializing tokenizer for type 1\n",
      "load: control-looking token:  32007 '<|end|>' was not control-type; this is probably a bug in the model. its type will be overridden\n",
      "load: control token:      2 '</s>' is not marked as EOG\n",
      "load: control token:      1 '<s>' is not marked as EOG\n",
      "load: control-looking token:  32000 '<|endoftext|>' was not control-type; this is probably a bug in the model. its type will be overridden\n",
      "load: printing all EOG tokens:\n",
      "load:   - 32000 ('<|endoftext|>')\n",
      "load:   - 32007 ('<|end|>')\n",
      "load: special tokens cache size = 67\n",
      "load: token to piece cache size = 0.1690 MB\n",
      "print_info: arch             = phi3\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 4096\n",
      "print_info: n_embd           = 3072\n",
      "print_info: n_layer          = 32\n",
      "print_info: n_head           = 32\n",
      "print_info: n_head_kv        = 32\n",
      "print_info: n_rot            = 96\n",
      "print_info: n_swa            = 0\n",
      "print_info: is_swa_any       = 0\n",
      "print_info: n_embd_head_k    = 96\n",
      "print_info: n_embd_head_v    = 96\n",
      "print_info: n_gqa            = 1\n",
      "print_info: n_embd_k_gqa     = 3072\n",
      "print_info: n_embd_v_gqa     = 3072\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-05\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 8192\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 2\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 10000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 4096\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: model type       = 3B\n",
      "print_info: model params     = 3.82 B\n",
      "print_info: general.name     = Phi3\n",
      "print_info: vocab type       = SPM\n",
      "print_info: n_vocab          = 32064\n",
      "print_info: n_merges         = 0\n",
      "print_info: BOS token        = 1 '<s>'\n",
      "print_info: EOS token        = 32000 '<|endoftext|>'\n",
      "print_info: EOT token        = 32007 '<|end|>'\n",
      "print_info: UNK token        = 0 '<unk>'\n",
      "print_info: PAD token        = 32000 '<|endoftext|>'\n",
      "print_info: LF token         = 13 '<0x0A>'\n",
      "print_info: EOG token        = 32000 '<|endoftext|>'\n",
      "print_info: EOG token        = 32007 '<|end|>'\n",
      "print_info: max token length = 48\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   1 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   2 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   3 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   4 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   5 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   6 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   7 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   8 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   9 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  10 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  11 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  12 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  13 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  14 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  15 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  16 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  17 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  18 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  19 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  20 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  21 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  22 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  23 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  24 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  25 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  26 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  27 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  28 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  29 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  30 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  31 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  32 assigned to device CPU, is_swa = 0\n",
      "load_tensors: tensor 'token_embd.weight' (f16) (and 194 others) cannot be used with preferred buffer type CPU_REPACK, using CPU instead\n",
      "load_tensors:   CPU_Mapped model buffer size =  7288.51 MiB\n",
      "....................................................................................\n",
      "llama_context: constructing llama_context\n",
      "llama_context: n_batch is less than GGML_KQ_MASK_PAD - increasing to 64\n",
      "llama_context: n_seq_max     = 1\n",
      "llama_context: n_ctx         = 2048\n",
      "llama_context: n_ctx_per_seq = 2048\n",
      "llama_context: n_batch       = 64\n",
      "llama_context: n_ubatch      = 8\n",
      "llama_context: causal_attn   = 1\n",
      "llama_context: flash_attn    = 0\n",
      "llama_context: kv_unified    = false\n",
      "llama_context: freq_base     = 10000.0\n",
      "llama_context: freq_scale    = 1\n",
      "llama_context: n_ctx_per_seq (2048) < n_ctx_train (4096) -- the full capacity of the model will not be utilized\n",
      "set_abort_callback: call\n",
      "llama_context:        CPU  output buffer size =     0.12 MiB\n",
      "create_memory: n_ctx = 2048 (padded)\n",
      "llama_kv_cache_unified: layer   0: dev = CPU\n",
      "llama_kv_cache_unified: layer   1: dev = CPU\n",
      "llama_kv_cache_unified: layer   2: dev = CPU\n",
      "llama_kv_cache_unified: layer   3: dev = CPU\n",
      "llama_kv_cache_unified: layer   4: dev = CPU\n",
      "llama_kv_cache_unified: layer   5: dev = CPU\n",
      "llama_kv_cache_unified: layer   6: dev = CPU\n",
      "llama_kv_cache_unified: layer   7: dev = CPU\n",
      "llama_kv_cache_unified: layer   8: dev = CPU\n",
      "llama_kv_cache_unified: layer   9: dev = CPU\n",
      "llama_kv_cache_unified: layer  10: dev = CPU\n",
      "llama_kv_cache_unified: layer  11: dev = CPU\n",
      "llama_kv_cache_unified: layer  12: dev = CPU\n",
      "llama_kv_cache_unified: layer  13: dev = CPU\n",
      "llama_kv_cache_unified: layer  14: dev = CPU\n",
      "llama_kv_cache_unified: layer  15: dev = CPU\n",
      "llama_kv_cache_unified: layer  16: dev = CPU\n",
      "llama_kv_cache_unified: layer  17: dev = CPU\n",
      "llama_kv_cache_unified: layer  18: dev = CPU\n",
      "llama_kv_cache_unified: layer  19: dev = CPU\n",
      "llama_kv_cache_unified: layer  20: dev = CPU\n",
      "llama_kv_cache_unified: layer  21: dev = CPU\n",
      "llama_kv_cache_unified: layer  22: dev = CPU\n",
      "llama_kv_cache_unified: layer  23: dev = CPU\n",
      "llama_kv_cache_unified: layer  24: dev = CPU\n",
      "llama_kv_cache_unified: layer  25: dev = CPU\n",
      "llama_kv_cache_unified: layer  26: dev = CPU\n",
      "llama_kv_cache_unified: layer  27: dev = CPU\n",
      "llama_kv_cache_unified: layer  28: dev = CPU\n",
      "llama_kv_cache_unified: layer  29: dev = CPU\n",
      "llama_kv_cache_unified: layer  30: dev = CPU\n",
      "llama_kv_cache_unified: layer  31: dev = CPU\n",
      "llama_kv_cache_unified:        CPU KV buffer size =   768.00 MiB\n",
      "llama_kv_cache_unified: size =  768.00 MiB (  2048 cells,  32 layers,  1/1 seqs), K (f16):  384.00 MiB, V (f16):  384.00 MiB\n",
      "llama_context: enumerating backends\n",
      "llama_context: backend_ptrs.size() = 1\n",
      "llama_context: max_nodes = 1560\n",
      "llama_context: worst-case: n_tokens = 8, n_seqs = 1, n_outputs = 0\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =    8, n_seqs =  1, n_outputs =    8\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =    1, n_seqs =  1, n_outputs =    1\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =    8, n_seqs =  1, n_outputs =    8\n",
      "llama_context:        CPU compute buffer size =     2.88 MiB\n",
      "llama_context: graph nodes  = 1126\n",
      "llama_context: graph splits = 1\n",
      "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | LLAMAFILE = 1 | OPENMP = 1 | REPACK = 1 | \n",
      "Model metadata: {'tokenizer.ggml.model': 'llama', 'phi3.feed_forward_length': '8192', 'general.name': 'Phi3', 'general.architecture': 'phi3', 'phi3.context_length': '4096', 'phi3.attention.head_count_kv': '32', 'phi3.embedding_length': '3072', 'phi3.block_count': '32', 'phi3.attention.head_count': '32', 'phi3.attention.layer_norm_rms_epsilon': '0.000010', 'phi3.rope.dimension_count': '96', 'tokenizer.ggml.eos_token_id': '32000', 'general.file_type': '1', 'tokenizer.ggml.pre': 'default', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.padding_token_id': '32000', 'tokenizer.ggml.add_bos_token': 'true', 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.chat_template': \"{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') %}{{'<|user|>' + '\\n' + message['content'] + '<|end|>' + '\\n' + '<|assistant|>' + '\\n'}}{% elif (message['role'] == 'assistant') %}{{message['content'] + '<|end|>' + '\\n'}}{% endif %}{% endfor %}\"}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') %}{{'<|user|>' + '\n",
      "' + message['content'] + '<|end|>' + '\n",
      "' + '<|assistant|>' + '\n",
      "'}}{% elif (message['role'] == 'assistant') %}{{message['content'] + '<|end|>' + '\n",
      "'}}{% endif %}{% endfor %}\n",
      "Using chat eos_token: <|endoftext|>\n",
      "Using chat bos_token: <s>\n"
     ]
    }
   ],
   "source": [
    "# import model \n",
    "from langchain_community.llms import LlamaCpp\n",
    "\n",
    "llm_pdf=LlamaCpp(\n",
    "    model_path=r\"C:\\Users\\ASUS\\Downloads\\Phi-3-mini-4k-instruct-fp16.gguf\",\n",
    "    n_gpu_layers=-1,\n",
    "    max_tokens=500,\n",
    "    seed=42,\n",
    "    verbose=True,\n",
    "    n_ctx=2048\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06d3d6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "130837bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the pdf\n",
    "from PyPDF2 import PdfReader\n",
    "pdf=r\"C:\\Users\\ASUS\\Downloads\\508_Ds\\Chapter 1 - Array List and Linked List.pdf\"\n",
    "pdf_reader=PdfReader(pdf)\n",
    "\n",
    "#get text in each pages\n",
    "text=\"\"\n",
    "for page in pdf_reader.pages:\n",
    "    text+=page.extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4735e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the chunks text (make it smaller)\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200, #Overlap helps the model not “forget” context when processing chunks separately.\n",
    "    length_function=len\n",
    ")\n",
    "chunks=text_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b0a206b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-huggingface 0.1.2 requires sentence-transformers>=2.6.0, but you have sentence-transformers 2.3.0 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install -q sentence_transformers==2.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1643b1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_11040\\3879360024.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b689dc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.12.0-cp313-cp313-win_amd64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from faiss-cpu) (2.2.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from faiss-cpu) (24.2)\n",
      "Downloading faiss_cpu-1.12.0-cp313-cp313-win_amd64.whl (18.2 MB)\n",
      "   ---------------------------------------- 0.0/18.2 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 5.0/18.2 MB 30.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 12.8/18.2 MB 34.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 18.2/18.2 MB 32.9 MB/s eta 0:00:00\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b990e012",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding the text chunks, creating Vector DAtabase\n",
    "from langchain.vectorstores import FAISS\n",
    "Vector_db=FAISS.from_texts(chunks,embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "db2f83f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RAG PROMPT\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "template=\"\"\"<|user|>\n",
    "Relevant Information:\n",
    "{context}\n",
    "\n",
    "Provide a concise answer the following question using the relevant and only information provided above.\n",
    "Use only sentences from the context.\n",
    " \n",
    "\n",
    "{question} <|end|>\n",
    "<|assistance|>\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt=PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"context\",\"question\"]\n",
    ")\n",
    "\n",
    "rag = RetrievalQA.from_chain_type(\n",
    "    llm=llm_pdf,\n",
    "    chain_type='stuff',\n",
    "    retriever=Vector_db.as_retriever(),\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\": prompt\n",
    "    },\n",
    "    verbose=True,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bc048f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 295 prefix-match hit, remaining 993 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =   53212.84 ms\n",
      "llama_perf_context_print: prompt eval time =   38633.66 ms /   993 tokens (   38.91 ms per token,    25.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =   23260.83 ms /   105 runs   (  221.53 ms per token,     4.51 tokens per second)\n",
      "llama_perf_context_print:       total time =   61950.98 ms /  1098 tokens\n",
      "llama_perf_context_print:    graphs reused =        194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'Define Circular Linked List and its advantage and disadvantage',\n",
       " 'result': 'A circular linked list is a variation of the linked list in which every node points to the next node, and the last node points back to the first node. This creates a loop that allows traversal in either direction from any point on the list. The advantage of a circular linked list includes being able to visit all elements from any starting point without needing to reach an end or beginning, as it forms a continuous cycle; however, its disadvantage is the potential for infinite loops if not managed correctly after removing nodes.',\n",
       " 'source_documents': [Document(id='ce05fa04-4ee0-4e53-9647-fd824f9581d4', metadata={}, page_content='▪Can insert a node only after a referenced node\\n▪Can remove a node only if we have a reference to \\nits predecessor node\\n▪Can traverse the list only in the forward direction\\n▪Above limitations removed by adding a \\nreference in each node to the previous node \\n(double -linked list)\\n4142•Every node: \\n–has a next reference variable and a back reference \\nvariable\\n–contains the address of the next node (except the \\nlast node) \\n–contains the address of the previous node (except \\nthe first node) \\n•Can be traversed in either direction 43\\uf07dAlinked listinwhich the last node points tothe first node is\\ncalled acircular linked list.\\n\\uf07dInacircular linked listwith more than one node, itisconvenient\\ntomake thereference variable first point tothelast node ofthe\\nlist.\\n\\uf07d\\n\\uf07dAdvantage :can traverse inforward orreverse direction even\\nafter you have passed thelastorfirst node .\\n◦Can visit allthelistelements from any starting point\\n\\uf07dCan never fallofftheend ofalist.\\n\\uf07dDisadvantage :infinite loop!'),\n",
       "  Document(id='fa93b16d-689a-43c5-94f0-bd5e7fb3e104', metadata={}, page_content='private Node newNode; // a reference variable for the new node\\n// Constructor: Construct an empty List \\npublic MyLinkedList()\\n{\\nhead = tail = newNode = null;\\n}\\n38// Return true if the List is empty\\npublic boolean isEmpty()\\n{ return head == null; }\\n// Return first element in the list\\npublic Object getFirst ()\\n{\\nif (isEmpty())\\nreturn null;\\nelse\\n{  \\nnewNode = head;\\nreturn newNode.data ;\\n}\\n}\\n39// Insert an Object at the front of the List\\n// If List is empty, head and tail will refer to\\n// the same object. Otherwise, head refers to new node.\\npublic void insertAtFront ( Object Item )\\n{\\nnewNode = new Node(Item);  // create new node\\nif (head == null) // If list is empty\\nhead = tail = newNode;\\nelse{\\nnewNode.next = head;\\nhead = newNode;      \\n}\\n}\\n40▪Limitations of a single -linked list include:\\n▪Can insert a node only after a referenced node\\n▪Can remove a node only if we have a reference to \\nits predecessor node\\n▪Can traverse the list only in the forward direction'),\n",
       "  Document(id='353a4aa7-aefb-4bd3-bcac-ed90839446b2', metadata={}, page_content='•a reference variable for the last node\\n•a reference variable for the new node \\nbeing added▪Steps to build a linked list forward:\\n▪Create a new node called newNode\\n▪If first is NULL, the list is empty so you can make first and last point \\nto newNode\\n▪If first is not NULL make last point to newNode and make last = \\nnewNode\\n33343536// Each node has two components: one to store the data; \\n// and one to store the address of the next node\\n// Node definition\\nclass Node {  \\nObject data;    \\nNode next;\\n// Constructor: Create a Node that refers to \\n// Object obj.\\nNode( Object obj ) \\n{ \\ndata = obj;\\nnext = null;\\n}\\n37// LinkedList definition\\npublic class MyLinkedList {\\nprivate Node head; // a reference variable for the first node\\nprivate Node tail; // a reference variable for the last node\\nprivate Node newNode; // a reference variable for the new node\\n// Constructor: Construct an empty List \\npublic MyLinkedList()\\n{\\nhead = tail = newNode = null;\\n}\\n38// Return true if the List is empty'),\n",
       "  Document(id='a5b3ce90-7ab2-427f-a4ca-9f77f5c7bf3f', metadata={}, page_content='▪Delete the last item from the list\\n21LINKED LISTS: SOME PROPERTIES▪Operations require traversal of the list.\\n▪Given a reference variable to the first node of the list, step \\nthrough each of the nodes of the list.\\n▪Traverse a list using a reference variable of the same type as \\nhead.\\n22LINKED LISTS: SOME PROPERTIES23LINKED LISTS: SOME PROPERTIES\\n24LINKED LISTS: SOME PROPERTIES\\nINSERTION\\n25//Insert the new node after p\\n▪Code Sequence I \\n▪newNode .link = p.link;\\n▪p.link = newNode;\\n▪Code Sequence II // Incorrect!\\n▪p.link = newNode;\\n▪newNode.link = p.link;\\n26\\uf07dCode sequence I produces the result shown \\nbelow\\n2728Node to be deleted is 34q29q = p.link;\\np.link = q.link;\\nq = null;\\nOr\\np.link = p.link.link;▪Part of the Java API\\n30\\n31\\n32What is needed to build a linked list forward:\\n•a reference variable for the first node\\n•a reference variable for the last node\\n•a reference variable for the new node \\nbeing added▪Steps to build a linked list forward:\\n▪Create a new node called newNode')]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag.invoke(\"Define Circular Linked List and its advantage and disadvantage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "df6acc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 10 prefix-match hit, remaining 1182 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =   53212.84 ms\n",
      "llama_perf_context_print: prompt eval time =   47364.07 ms /  1182 tokens (   40.07 ms per token,    24.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =   28170.88 ms /   127 runs   (  221.82 ms per token,     4.51 tokens per second)\n",
      "llama_perf_context_print:       total time =   75608.68 ms /  1309 tokens\n",
      "llama_perf_context_print:    graphs reused =        231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'Define mechanical engineer',\n",
       " 'result': 'Unfortunately, the provided information does not specifically define what a mechanical engineer is. However, based on general knowledge within the context of engineering and data structures:\\n\\nA mechanical engineer may be involved in designing mechanical systems and components that could include elements such as gears or linkages (similar to linked lists), although this topic\\'s focus was more about programming concepts rather than specific job roles like a mechanical engineer. To define a mechanical engineer, we would typically say:\\n\\n\"A mechanical engineer is a professional who applies principles of physics and materials science for the design, analysis, manufacturing, and maintenance of mechanical systems.\"',\n",
       " 'source_documents': [Document(id='a5b3ce90-7ab2-427f-a4ca-9f77f5c7bf3f', metadata={}, page_content='▪Delete the last item from the list\\n21LINKED LISTS: SOME PROPERTIES▪Operations require traversal of the list.\\n▪Given a reference variable to the first node of the list, step \\nthrough each of the nodes of the list.\\n▪Traverse a list using a reference variable of the same type as \\nhead.\\n22LINKED LISTS: SOME PROPERTIES23LINKED LISTS: SOME PROPERTIES\\n24LINKED LISTS: SOME PROPERTIES\\nINSERTION\\n25//Insert the new node after p\\n▪Code Sequence I \\n▪newNode .link = p.link;\\n▪p.link = newNode;\\n▪Code Sequence II // Incorrect!\\n▪p.link = newNode;\\n▪newNode.link = p.link;\\n26\\uf07dCode sequence I produces the result shown \\nbelow\\n2728Node to be deleted is 34q29q = p.link;\\np.link = q.link;\\nq = null;\\nOr\\np.link = p.link.link;▪Part of the Java API\\n30\\n31\\n32What is needed to build a linked list forward:\\n•a reference variable for the first node\\n•a reference variable for the last node\\n•a reference variable for the new node \\nbeing added▪Steps to build a linked list forward:\\n▪Create a new node called newNode'),\n",
       "  Document(id='bcde86e3-e6c6-441a-985d-7bec38718873', metadata={}, page_content='Structures Using Java .\\n▪Do exercise on implementing ArrayList class:\\n▪LAB 2, Lab Activities, Exercise 1 -Exercise 10\\n15\\uf07dArray List:\\n\\uf096Fast access to elements \\n\\uf096Slower insertion/deletion of elements\\n\\uf096add and remove methods operate inlinear time because\\nthey require aloop toshift elements inthe underlying\\narray .\\n\\uf07dLinked list:\\n\\uf096Slower access toelements\\n\\uf096Fast insertion/deletion ofelements\\n\\uf096ability toadd orremove items anywhere inthe listin\\nconstant time .\\n16▪Definition :alist ofitems, called nodes, in\\nwhich theorder ofthenodes isdetermined\\nbytheaddress, called thelink, stored ineach\\nnode .\\n▪Every node inalinked list has two\\ncomponents :\\n▪one tostore relevant information\\n▪one tostore address (the link )ofnext node inlist\\n17LINKED LISTS▪Address offirst node inlist stored inseparate\\nlocation, called thehead orfirst\\n▪Data type ofeach node depends onthe specific\\napplication —kind ofdata being processed\\n▪link component ofeach node isareference variable'),\n",
       "  Document(id='4ee9f32f-ad2c-43de-a027-bcecc7ef8053', metadata={}, page_content='TOPIC 1 LIST\\nArray List & Linked List1\\nZulaile Mabni▪Learn about the List interface\\n▪Learn about array list\\n▪Learn about linked list\\n▪Learn the basic properties ofarray list and\\nlinked list\\n▪Discover how tobuild and manipulate anarray\\nlistand alinked list\\n2▪The Collection interface specifies asubset ofthe\\nmethods specified intheListinterface .\\n▪Collection interface isthe root ofthe collection\\nhierarchy\\n▪Two branches :one rooted bytheListinterface and\\ntheother bytheSetinterface\\n3\\uf07dList: A collection of elements of the same type.\\n◦Example:\\n\\uf096A list of students\\n\\uf096A list of books\\n\\uf07dAllowed operations on the List interface include:\\n◦Finding a specified target\\n◦Adding an element to either end\\n◦Removing an item from either end\\n◦Traversing the list structure without a subscript\\n45\\uf07dThe array listgives you additional capability beyond what anarray\\nprovides .\\n\\uf07dThe length inanarray isfixed, whereas, thelength inanarray listcan\\nincrease ordecrease .'),\n",
       "  Document(id='0e183d14-4a29-46cc-b78b-4a1ef2667195', metadata={}, page_content='after you have passed thelastorfirst node .\\n◦Can visit allthelistelements from any starting point\\n\\uf07dCan never fallofftheend ofalist.\\n\\uf07dDisadvantage :infinite loop!\\n4445\\uf07dKoffman E.,Wolfgang P.,Objects, Abstraction, Data\\nStructures And Design Using Java, John Wiley &Sons,\\n2005 .\\n\\uf07dMalik D.S.,Nair P.S.,Data Structures Using Java, Course\\nTechnology, 2003 .\\n\\uf07dWeiss Mark Allen, Data Structures &Algorithm Analysis in\\nC++, Pearson Education International Inc,2003 .\\n\\uf07dhttp://www .oracle .com/technetwork/java/index .html\\n46')]}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag.invoke(\"Define mechanical engineer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e1021f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
